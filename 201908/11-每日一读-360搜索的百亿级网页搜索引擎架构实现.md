[TOC]
# 写在前面的话
> Stay Hungry Stay Foolish！！！
> 每天进步一点点！！！

《每日一读》是博主每日学习的一篇文章所记录的笔记，大多数是提取文章中关键内容而成；文章类型不限，内容不限。

意义：培养自己的阅读能力，学习更多的知识

**郑重声明**：如果涉及到文章侵权深感抱歉，请及时联系我我会第一时间删除，谢谢！！

# 总结
一个网站搜索引擎其面临的数据量是PB级别的，其背后的技术架构也很是值得学习的。核心的目标在于如何给用户呈现最符合用户预期的内容，关键要克服的问题个人认为包含以下几项：
1. 时效性
2. 页面相关性
3. 数据存储
4. 索引的建立

这篇文章让我学习到一个搜索引擎内部到底是怎么运作的？索引如何建立？检索策略？收益颇深！

# 正文

- [360 搜索的百亿级网页搜索引擎架构实现](https://www.infoq.cn/article/pF3_wx3rQ43VYMpLdAPC)

## 如何设计搜索引擎

### 基础检索
一个用户请求过来之后，整个搜索引擎的工作流程大致如下：

![](https://upload-images.jianshu.io/upload_images/4589271-04410c1f4614d7ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


首先用切词组件做分词，把 query 分成多个 word，然后多个 word 会从我们的倒排索引里面获取倒排拉链，在倒排拉链的基础上，会做求交计算来拿到所有命中的 doc list。拿到 doc list 之后，我们希望能够把优质的网页反馈给用户，这时候我们还需要做 rank 计算。rank 计算就是拿倒排里面的一些位置索引信息，包括在正排里面拿一些 rank 的属性特征信息做打分，最终会把分数比较高的 Top N 结果反馈用户。当然在前端 web 页面展示的时候，需要从正排中提取摘要信息，展示给用户。这就是整个的检索过程。

### 基础索引

![](https://upload-images.jianshu.io/upload_images/4589271-59fe70ab008fb923.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


网站内容：
1. 属性：如网站分类信息、rank相关信息等
2. word：将正文分词的结果

- 正排索引：以doc为key，属性和word列表为value
- 倒排索引：以doc里的word为key，doclist为value

### 检索模型
![](https://upload-images.jianshu.io/upload_images/4589271-cc4ddcb08eb8bbbf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

【query分析】

1. 检索粒度：词、短语、组合词；粒度更大结果更优质
2. Term属性分析
    - weight：“`北京 长城`”显然长城的权重更高
    - 紧密性：query的关联关系；如“`北京到上海的机票怎么买？多少钱？`”，具有方向性
3. query需求分析：用户搜索的意图；例如“`非诚勿扰`”，既有电影也有综艺，结合时效性、用户画像等因素拟合用户最强烈需求

【查询策略】

1. 检索资源：网页质量筛选、内容质量打分、内容分类
2. 确定相关网页集合：求交计算的过程。query命中、term命中
3. 结果相关性计算：
    - term与文章相关性
    - term紧密度计算：term在文章中的分布情况
4. 重查策略：原因是检索结果少或结果质量低；手段有增加检索资源、减少不必要的term、query改写及扩展

## 关键技术
![](https://upload-images.jianshu.io/upload_images/4589271-1f2f82d2a87e43cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


搜索架构中最重要的两个核心模块为：
1. 离线建库：数据爬取、建索引
2. 在线检索：快速检索、检索策略

### 离线建库
1. 索引划分：几P的索引数据；设计类似跳跃表？
2. 索引创建：Map-Reduce任务
3. 索引更新：增量数据、rank更新

### 在线检索
1. 分布式服务：用于将query分析的结果发送到索引库和收集结果，以及做一些定制策略
2. 请求广播：广播到各个索引单元
3. 负载均衡：系统稳定性问题

### 架构
![](https://upload-images.jianshu.io/upload_images/4589271-02770d28e9eeafc6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


1. 离线建库：
    - 分片：url转为64位md5为key（均匀分布）【提升建索引速度】
    - 网页类型划分：重要和普通
    - 实时数据补充：通过Storm实时生成实时索引和天级索引
2. 在线检索：
    - query分析
    - 广播到所有索引库，其内部做求交运算和基础相关性计算
    - 收集到结果后，服务节点还可能做一些策略


## 网页索引组织模式
![](https://upload-images.jianshu.io/upload_images/4589271-6f3e3d554748ba41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


【正排索引】
独立更新的问题：更新频率高

设计思路：
1. url 列表中它的位置就代表 doc id，数据属性的存储会按照`固定长度`的数据块存放在数据文件中。数据块的下方位置就是它对应的 doc id 信息
2. 稀疏信息问题方案：`变长`的数据块和头部信息；头信息主要是用来存储它在数据文件里面的位置信息，整个头信息和 url 列表是一 一对应的

【倒排索引】

两个问题：

1. 正排到倒排：数据量会剧增，doclist重复度高
2. 需要支持范围查找

设计思路：
1. 压缩：将倒排表划分成多个块，块进行压缩；检索时，逐步解压块，满足用户需求时停止检索
2. 分段：每个段会记录每一个动态表块的最小的 id 和最大的 id 来表示范围

## 网页检索和相关性

### 求交模型
![](https://upload-images.jianshu.io/upload_images/4589271-0bc8f987a38f0f65.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


- 最短拉链求交：减少求交次数
- 内部查找算法：二分查找+步长策略

### 基础相关性
【基础赋权】
![](https://upload-images.jianshu.io/upload_images/4589271-e95656e1f145000d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

基础赋权是来解决 query 中的每一个 term 和它对应的文章的权重计算。

- TF：代表承载信息量，即这个 word 在文章中出现的次数；
- IDF：代表信息承载能力，即这个 word 在全网的出现次数
- [BM25](https://www.zybuluo.com/zhuanxu/note/974675)：在TF\*IDF的基础上，加上了文章长度和term weight
- Term等级/词性：挖掘出每篇文章的主题、关键词，以及关键词的一些限定词这些信息，对term分级及词性信息

【紧密度计算】
![](https://upload-images.jianshu.io/upload_images/4589271-d5987183643fc581.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


紧密度计算就是用户的 query 过来之后，针对 query 的分词，一是相邻 word 之间的紧密程度在文章中是怎样的分布；二是跨 term 的信息，那也就是方向的信息。

通过计算文章中query中相邻word之间的距离来确定方向性。例如上图中取B为中心点，第二个A是在B后面，则A和B的距离就会拉长


